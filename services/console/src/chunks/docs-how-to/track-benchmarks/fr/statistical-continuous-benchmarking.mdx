import RunMainStatistical from "../run-main-statistical.mdx";
import RunFeatureStatistical from "../run-feature-statistical.mdx";

## Benchmarking Continu Statistique

Partant de l√† o√π nous en √©tions dans les tutoriels
[Quick Start][quick start] et [Docker Self-Hosted][docker self-hosted],
ajoutons le [Benchmarking Continu Statistique][continuous benchmarking] √† notre projet `claimed`.

> üê∞ Assurez-vous d'avoir
> [cr√©√© un jeton API et de l'avoir d√©fini comme variable d'environnement `BENCHER_API_TOKEN`][create an api token]
> avant de continuer !

[quick start]: /fr/docs/tutorial/quick-start/
[docker self-hosted]: /fr/docs/tutorial/docker/
[continuous benchmarking]: /fr/docs/explanation/continuous-benchmarking/
[create an api token]: /fr/docs/tutorial/quick-start/#create-an-api-token

Nous sommes maintenant pr√™ts √† ex√©cuter nos benchmarks dans CI.
√âtant donn√© que chaque environnement CI est un peu diff√©rent,
l'exemple suivant est con√ßu pour √™tre plus illustratif que pratique.
Pour des exemples plus sp√©cifiques, consultez [Benchmarking Continu dans GitHub Actions][github actions]
et [Benchmarking Continu dans GitLab CI/CD][gitlab ci/cd].

[github actions]: /fr/docs/how-to/github-actions/
[gitlab ci/cd]: /fr/docs/how-to/gitlab-ci-cd/

Tout d'abord, nous devons cr√©er et maintenir une r√©f√©rence historique pour notre branche `main` en √©valuant chaque changement dans CI :

<RunMainStatistical />

1. Utilisez la sous-commande CLI <code><a href="/fr/docs/explanation/bencher-run/">bencher run</a></code>
   pour ex√©cuter les benchmarks de votre branche `main`.
   Voir [la sous-commande CLI `bencher run`][bencher run] pour un aper√ßu complet.
   (ex: `bencher run`)
2. D√©finissez l'option `--project` sur le slug du Projet.
   Voir [la documentation `--project`][project option] pour plus de d√©tails.
   (ex: `--project project-abc4567-wxyz123456789`)
3. D√©finissez l'option `--branch` sur le nom de la branche de base.
   Voir [la documentation `--branch`][branch option] pour un aper√ßu complet.
   (ex: `--branch main`)
4. D√©finissez l'option `--testbed` sur le nom du Testbed du coureur CI.
   Voir [la documentation `--testbed`][testbed option] pour plus de d√©tails.
   (ex: `--testbed ci-runner`)
5. D√©finissez le Seuil pour la branche `main`, le Testbed `ci-runner` et la Mesure `latency` :
   1. D√©finissez l'option `--threshold-measure` sur la Mesure `latency` int√©gr√©e g√©n√©r√©e par <code><a href="/fr/docs/reference/bencher-metric-format/#bencher-mock">bencher mock</a></code>.
   Voir [la documentation `--threshold-measure`][threshold measure option] pour plus de d√©tails.
   (ex: `--threshold-measure latency`)
   2. D√©finissez l'option `--threshold-test` sur un test t de Student (`t_test`).
   Voir [la documentation `--threshold-test`][threshold test option] pour un aper√ßu complet.
   (ex: `--threshold-test t_test`)
   3. D√©finissez l'option `--threshold-max-sample-size` sur la taille d'√©chantillon maximale de `64`.
   Voir [la documentation `--threshold-max-sample-size`][threshold max sample size] pour plus de d√©tails.
   (ex: `--threshold-max-sample-size 64`)
   4. D√©finissez l'option `--threshold-upper-boundary` sur la Limite Sup√©rieure de `0.99`.
   Voir [la documentation `--threshold-upper-boundary`][threshold upper boundary] pour plus de d√©tails.
   (ex: `--threshold-upper-boundary 0.99`)
   5. Activez le drapeau `--thresholds-reset` pour que seul le Seuil sp√©cifi√© soit actif.
   Voir [la documentation `--thresholds-reset`][thresholds reset] pour un aper√ßu complet.
   (ex: `--thresholds-reset`)
6. Activez le drapeau `--err` pour que la commande √©choue si une Alerte est g√©n√©r√©e.
   Voir [la documentation `--err`][alert err] pour un aper√ßu complet.
   (ex: `--err`)
7. D√©finissez l'option `--adapter` sur [Bencher Metric Format JSON (`json`)][bmf] g√©n√©r√© par <code><a href="/fr/docs/reference/bencher-metric-format/#bencher-mock">bencher mock</a></code>.
   Voir [les adaptateurs de harnais de benchmark][adapter json] pour un aper√ßu complet.
   (ex: `--adapter json`)
8. Sp√©cifiez les arguments de commande de benchmark.
   Voir [commande de benchmark][command argument] pour un aper√ßu complet.
   (ex: `bencher mock`)

La premi√®re fois que cette commande est ex√©cut√©e dans CI,
elle cr√©era la branche `main` si elle n'existe pas encore.
La nouvelle `main` n'aura _pas_ de point de d√©part ni de donn√©es existantes.
Un Seuil sera cr√©√© pour la branche `main`, le Testbed `ci-runner` et la Mesure `latency`.
Lors des ex√©cutions ult√©rieures, de nouvelles donn√©es seront ajout√©es √† la branche `main`.
Le Seuil sp√©cifi√© sera ensuite utilis√© pour d√©tecter les r√©gressions de performance.

[bencher run]: /fr/docs/explanation/bencher-run/
[project option]: /fr/docs/explanation/bencher-run/#--project-project
[branch option]: /fr/docs/explanation/branch-selection/#--branch-branch
[testbed option]: /fr/docs/explanation/bencher-run/#--testbed-testbed
[threshold measure option]: /fr/docs/explanation/thresholds/#--threshold-measure-measure
[threshold test option]: /fr/docs/explanation/thresholds/#--threshold-test-test
[threshold max sample size]: /fr/docs/explanation/thresholds/#--threshold-max-sample-size-size
[threshold upper boundary]: /fr/docs/explanation/thresholds/#--threshold-upper-boundary-boundary
[thresholds reset]: /fr/docs/explanation/thresholds/#--thresholds-reset
[alert err]: /fr/docs/explanation/thresholds/#--err
[bmf]: /fr/docs/reference/bencher-metric-format/
[adapter json]: /fr/docs/explanation/adapters/#-json
[command argument]: /fr/docs/explanation/bencher-run/#benchmark-command

Nous sommes maintenant pr√™ts √† d√©tecter les r√©gressions de performance dans CI.
Voici comment nous suivrions les performances d'une nouvelle branche de fonctionnalit√©s dans CI, judicieusement nomm√©e `feature-branch` :

<RunFeatureStatistical />

1. Utilisez la sous-commande CLI <code><a href="/fr/docs/explanation/bencher-run/">bencher run</a></code>
   pour ex√©cuter les benchmarks de votre branche `feature-branch`.
   Voir [la sous-commande CLI `bencher run`][bencher run] pour un aper√ßu complet.
   (ex: `bencher run`)
2. D√©finissez l'option `--project` sur le slug du Projet.
   Voir [la documentation `--project`][project option] pour plus de d√©tails.
   (ex: `--project project-abc4567-wxyz123456789`)
3. D√©finissez l'option `--branch` sur le nom de la branche de fonctionnalit√©.
   Voir [la documentation `--branch`][branch option] pour un aper√ßu complet.
   (ex: `--branch feature-branch`)
4. D√©finissez le Point de D√©part pour la branche `feature-branch` :
   1. D√©finissez l'option `--start-point` sur le point de d√©part de la branche de fonctionnalit√©.
   Voir [la documentation `--start-point`][start point] pour un aper√ßu complet.
   (ex: `--start-point main`)
   2. D√©finissez l'option `--start-point-hash` sur le hachage `git` du point de d√©part de la branche de fonctionnalit√©.
   Voir [la documentation `--start-point-hash`][start point hash] pour un aper√ßu complet.
   (ex: `--start-point-hash 32ae...dd8b`)
   3. Activez le drapeau `--start-point-clone-thresholds` pour cloner les Seuils du point de d√©part.
   Voir [la documentation `--start-point-clone-thresholds`][start point clone thresholds] pour un aper√ßu complet.
   (ex: `--start-point-clone-thresholds`)
   4. Activez le drapeau `--start-point-reset` pour toujours r√©initialiser la Branche au point de d√©part.
   Cela emp√™chera la d√©rive des donn√©es de benchmark.
   Voir [la documentation `--start-point-reset`][start point reset] pour un aper√ßu complet.
   (ex: `--start-point-reset`)
5. D√©finissez l'option `--testbed` sur le nom du Testbed.
   Voir [la documentation `--tested`][testbed option] pour plus de d√©tails.
   (ex: `--testbed ci-runner`)
6. Activez le drapeau `--err` pour que la commande √©choue si une Alerte est g√©n√©r√©e.
   Voir [la documentation `--err`][alert err] pour un aper√ßu complet.
   (ex: `--err`)
7. D√©finissez l'option `--adapter` sur [Bencher Metric Format JSON (`json`)][bmf] g√©n√©r√© par <code><a href="/fr/docs/reference/bencher-metric-format/#bencher-mock">bencher mock</a></code>.
   Voir [les adaptateurs de harnais de benchmark][adapter json] pour un aper√ßu complet.
   (ex: `--adapter json`)
8.  Sp√©cifiez les arguments de commande de benchmark.
   Voir [commande de benchmark][command argument] pour un aper√ßu complet.
   (ex: `bencher mock`)

La premi√®re fois que cette commande est ex√©cut√©e dans CI,
Bencher cr√©era la branche `feature-branch` car elle n'existe pas encore.
La nouvelle branche `feature-branch` utilisera la branche `main`
au hachage `32aea434d751648726097ed3ac760b57107edd8b` comme point de d√©part.
Cela signifie que `feature-branch` aura une copie de toutes les donn√©es et [Seuils][thresholds]
de la branche `main` pour comparer les r√©sultats de `bencher mock`.
Lors de toutes les ex√©cutions ult√©rieures, Bencher r√©initialisera la branche `feature-branch` au point de d√©part,
et utilisera les donn√©es et les Seuils de la branche `main` pour d√©tecter les r√©gressions de performance.

[start point]: /fr/docs/explanation/branch-selection/#--start-point-branch
[start point hash]: /fr/docs/explanation/branch-selection/#--start-point-hash-hash
[start point clone thresholds]: /fr/docs/explanation/branch-selection/#--start-point-clone-thresholds
[start point reset]: /fr/docs/explanation/branch-selection/#--start-point-reset
[thresholds]: /fr/docs/explanation/thresholds/