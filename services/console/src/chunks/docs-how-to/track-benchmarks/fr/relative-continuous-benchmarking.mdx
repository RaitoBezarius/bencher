import GitCheckoutMain from "../git-checkout-main.mdx";
import RunMainRelative from "../run-main-relative.mdx";
import GitCheckoutFeature from "../git-checkout-feature.mdx";
import RunFeatureRelative from "../run-feature-relative.mdx";

## Benchmarking Continu Relatif

En reprenant l√† o√π nous nous √©tions arr√™t√©s dans les tutoriels [D√©marrage Rapide][quick start] et [Docker Auto-H√©berg√©][docker self-hosted], ajoutons le [Benchmarking Continu][continuous benchmarking] Relatif √† notre projet `Sauvegarder Walter White`.

> üê∞ Assurez-vous d'avoir [cr√©√© un jeton API et de l'avoir d√©fini comme variable d'environnement `BENCHER_API_TOKEN`][create an api token] avant de continuer !

[quick start]: /fr/docs/tutorial/quick-start/
[docker self-hosted]: /fr/docs/tutorial/docker/
[continuous benchmarking]: /fr/docs/explanation/continuous-benchmarking/
[create an api token]: /fr/docs/tutorial/quick-start/#create-an-api-token

Le Benchmarking Continu Relatif r√©alise une comparaison c√¥te √† c√¥te de deux versions de votre code. Cela peut √™tre utile dans des environnements CI/CD bruyants, o√π les ressources disponibles peuvent varier consid√©rablement entre les ex√©cutions. Dans cet exemple, nous comparerons les r√©sultats d'ex√©cution sur la branche `main` aux r√©sultats d'ex√©cution sur une branche fonctionnelle, justement nomm√©e `feature-branch`. Comme chaque environnement CI est un peu diff√©rent, l'exemple suivant est davantage illustratif que pratique. Pour des exemples plus sp√©cifiques, voir [Benchmarking Continu dans GitHub Actions][github actions] et [Benchmarking Continu dans GitLab CI/CD][gitlab ci/cd].

[github actions]: /fr/docs/how-to/github-actions/
[gitlab ci/cd]: /fr/docs/how-to/gitlab-ci-cd/

Tout d'abord, nous devons basculer sur la branche `main` avec `git` dans CI :

<GitCheckoutMain />

Ensuite, nous avons besoin de lancer nos benchmarks sur la branche `main` dans CI :

<RunMainRelative />

1. Utilisez la sous-commande CLI <code><a href="/fr/docs/explanation/bencher-run/">bencher run</a></code> pour ex√©cuter vos benchmarks de la branche `main`. Voir [un aper√ßu complet de la sous-commande CLI `bencher run`][bencher run]. (ex : `bencher run`)
2. D√©finissez l'option `--project` √† l'identifiant du Projet. Voir [les d√©tails des docs `--project`][project option]. (ex : `--project project-abc4567-wxyz123456789`)
3. D√©finissez l'option `--branch` au nom de la Branche de base. Voir [un aper√ßu complet des docs `--branch`][branch option]. (ex : `--branch main`)
4. D√©finissez l'indicateur `--start-point-reset` pour toujours r√©initialiser la Branche de base. Cela garantira que toutes les donn√©es de benchmark proviennent de l'ex√©cuteur CI actuel. Voir [un aper√ßu complet des docs `--start-point-reset`][start point reset]. (ex : `--start-point-reset`)
5. D√©finissez l'option `--testbed` au nom du Testbed de l'ex√©cuteur CI. Voir [les d√©tails des docs `--testbed`][testbed option]. (ex : `--testbed ci-runner`)
6. D√©finissez l'option `--adapter` au [Format de M√©trique Bencher JSON (`json`)][bmf] g√©n√©r√© par <code><a href="/fr/docs/reference/bencher-metric-format/#bencher-mock">bencher mock</a></code>. Voir [un aper√ßu complet des adaptateurs de harnais de benchmark][adapter json]. (ex : `--adapter json`)
7. Sp√©cifiez les arguments de la commande de benchmark. Voir [un aper√ßu complet de la commande de benchmark][command argument]. (ex : `bencher mock`)

La premi√®re fois que cette commande est ex√©cut√©e dans CI, elle cr√©era la Branche `main` car elle n'existe pas encore. La nouvelle `main` n'aura _pas_ de point de d√©part, de donn√©es existantes, ni de Seuils. Lors des ex√©cutions subs√©quentes, l'ancien [Head][head] de la `main` sera remplac√©, et un nouveau [Head][head] de la `main` sera cr√©√© sans point de d√©part, donn√©es existantes, ni Seuils.

[bencher run]: /fr/docs/explanation/bencher-run/
[project option]: /fr/docs/explanation/bencher-run/#--project-project
[branch option]: /fr/docs/explanation/branch-selection/#--branch-branch
[start point reset]: /fr/docs/explanation/branch-selection/#--start-point-reset
[testbed option]: /fr/docs/explanation/bencher-run/#--testbed-testbed
[bmf]: /fr/docs/reference/bencher-metric-format/
[adapter json]: /fr/docs/explanation/adapters/#-json
[command argument]: /fr/docs/explanation/bencher-run/#benchmark-command
[head]: /fr/docs/explanation/benchmarking/#head

Ensuite, nous devons basculer sur la branche `feature-branch` avec `git` dans CI :

<GitCheckoutFeature />

Enfin, nous sommes pr√™ts √† ex√©cuter nos benchmarks de `feature-branch` dans CI :

<RunFeatureRelative />

1. Utilisez la sous-commande CLI <code><a href="/fr/docs/explanation/bencher-run/">bencher run</a></code> pour ex√©cuter vos benchmarks de `feature-branch`. Voir [un aper√ßu complet de la sous-commande CLI `bencher run`][bencher run]. (ex : `bencher run`)
2. D√©finissez l'option `--project` √† l'identifiant du Projet. Voir [les d√©tails des docs `--project`][project option]. (ex : `--project project-abc4567-wxyz123456789`)
3. D√©finissez l'option `--branch` au nom de la Branche fonctionnelle. Voir [un aper√ßu complet des docs `--branch`][branch option]. (ex : `--branch feature-branch`)
4. D√©finissez le Point de D√©part pour la Branche `feature-branch` :
   1. D√©finissez l'option `--start-point` au point de d√©part de la Branche fonctionnelle. Voir [un aper√ßu complet des docs `--start-point`][start point]. (ex : `--start-point main`)
   2. D√©finissez l'indicateur `--start-point-reset` pour toujours r√©initialiser la Branche au point de d√©part. Cela n'utilisera que les derniers r√©sultats de benchmark relatifs. Voir [un aper√ßu complet des docs `--start-point-reset`][start point reset]. (ex : `--start-point-reset`)
5. D√©finissez l'option `--testbed` au nom du Testbed de l'ex√©cuteur CI. Voir [les d√©tails des docs `--testbed`][testbed option]. (ex : `--testbed ci-runner`)
6. D√©finissez le Seuil pour la Branche `feature-branch`, le Testbed `ci-runner`, et la Mesure `latency` :
   1. D√©finissez l'option `--threshold-measure` √† la Mesure int√©gr√©e `latency` g√©n√©r√©e par <code><a href="/fr/docs/reference/bencher-metric-format/#bencher-mock">bencher mock</a></code>. Voir [les d√©tails des docs `--threshold-measure`][threshold measure option]. (ex : `--threshold-measure latency`)
   2. D√©finissez l'option `--threshold-test` √† un pourcentage de base (`percentage`). Voir [un aper√ßu complet des docs `--threshold-test`][threshold test option]. (ex : `--threshold-test percentage`)
   3. D√©finissez l'option `--threshold-upper-boundary` √† la Limite Sup√©rieure de `0.25`. Voir [les d√©tails des docs `--threshold-upper-boundary`][threshold upper boundary]. (ex : `--threshold-upper-boundary 0.25`)
   4. D√©finissez l'indicateur `--thresholds-reset` pour que seul le Seuil sp√©cifi√© soit actif. Voir [un aper√ßu complet des docs `--thresholds-reset`][thresholds reset]. (ex : `--thresholds-reset`)
7. D√©finissez l'indicateur `--err` pour √©chouer √† la commande si une Alarme est g√©n√©r√©e. Voir [un aper√ßu complet des docs `--err`][alert err]. (ex : `--err`)
8. D√©finissez l'option `--adapter` au [Format de M√©trique Bencher JSON (`json`)][bmf] g√©n√©r√© par <code><a href="/fr/docs/reference/bencher-metric-format/#bencher-mock">bencher mock</a></code>. Voir [un aper√ßu complet des adaptateurs de harnais de benchmark][adapter json]. (ex : `--adapter json`)
9. Sp√©cifiez les arguments de la commande de benchmark. Voir [un aper√ßu complet de la commande de benchmark][command argument]. (ex : `bencher mock`)

Chaque fois que cette commande est ex√©cut√©e dans CI, elle compare les r√©sultats de `feature-branch` uniquement avec les r√©sultats les plus r√©cents de `main`. Le Seuil sp√©cifi√© est alors utilis√© pour d√©tecter les r√©gressions de performance.

[start point]: /fr/docs/explanation/branch-selection/#--start-point-branch
[start point reset]: /fr/docs/explanation/branch-selection/#--start-point-reset
[threshold measure option]: /fr/docs/explanation/thresholds/#--threshold-measure-measure
[threshold test option]: /fr/docs/explanation/thresholds/#--threshold-test-test
[threshold upper boundary]: /fr/docs/explanation/thresholds/#--threshold-upper-boundary-boundary
[thresholds reset]: /fr/docs/explanation/thresholds/#--thresholds-reset
[alert err]: /fr/docs/explanation/thresholds/#--err