import TestGameCode from "../test-game-code.mdx";
import PipenvShellOutput from "../../pipenv-shell-output.mdx";
import PipenvInstallOutput from "../pipenv-install-output.mdx";
import PytestGameOutput from "../pytest-game-output.mdx";

## √âvaluation comparative de FizzBuzz

Afin de faire l'√©valuation comparative de notre code, nous devons cr√©er une fonction de test qui ex√©cute notre benchmark.
En bas de `game.py`, ajoutez le code suivant :

<TestGameCode />

- Cr√©ez une fonction nomm√©e `test_game` qui prend en param√®tre un fixture `benchmark` de `pytest-benchmark`.
- Cr√©ez une fonction `run_game` qui it√®re de `1` √† `100` inclusivement.
  - Pour chaque nombre, appelez `play_game`, avec `should_print` d√©fini sur `False`.
- Passez la fonction `run_game` au coureur `benchmark`.

Nous devons maintenant configurer notre projet pour ex√©cuter nos benchmarks.

Cr√©ez un nouvel environnement virtuel avec `pipenv` :

<PipenvShellOutput />

Installez `pytest-benchmark` dans ce nouvel environnement `pipenv` :

<PipenvInstallOutput />

Nous sommes maintenant pr√™ts √† √©valuer notre code, ex√©cutez `pytest game.py` :

<PytestGameOutput />

> üê∞ Laitue faire bouger les betteraves ! Nous avons nos premi√®res m√©triques de benchmark !

Enfin, nous pouvons reposer nos t√™tes de d√©veloppeurs fatigu√©es...
Je plaisante, nos utilisateurs veulent une nouvelle fonctionnalit√© !